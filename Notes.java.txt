package com.programyourhome.voice;

import java.io.BufferedInputStream;
import java.io.File;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.List;
import java.util.function.BiConsumer;
import java.util.stream.Collectors;

import javax.inject.Inject;
import javax.sound.sampled.AudioFormat;
import javax.sound.sampled.AudioInputStream;
import javax.sound.sampled.AudioSystem;
import javax.sound.sampled.BooleanControl;
import javax.sound.sampled.CompoundControl;
import javax.sound.sampled.Control;
import javax.sound.sampled.EnumControl;
import javax.sound.sampled.FloatControl;
import javax.sound.sampled.Line;
import javax.sound.sampled.Mixer;
import javax.sound.sampled.SourceDataLine;
import javax.sound.sampled.TargetDataLine;

import org.apache.commons.lang3.StringUtils;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.ApplicationContext;
import org.springframework.stereotype.Component;

import com.programyourhome.voice.config.ConfigUtil;
import com.programyourhome.voice.config.VoiceControlConfigHolder;
import com.programyourhome.voice.detection.AudioDetector;
import com.programyourhome.voice.detection.AudioFrame;
import com.programyourhome.voice.detection.ClapDetector;
import com.programyourhome.voice.detection.NonSilenceDetector;
import com.programyourhome.voice.detection.SpeechDetector;
import com.programyourhome.voice.format.PyhAudioFormat;
import com.programyourhome.voice.model.AnswerResult;
import com.programyourhome.voice.model.AnswerResultImpl;
import com.programyourhome.voice.model.AnswerResultType;
import com.programyourhome.voice.model.ListenResult;
import com.programyourhome.voice.model.ListenResultType;
import com.programyourhome.voice.model.question.Question;

@Component
public class Notes {

    public static void main(String[] args) throws Exception {
        for (Mixer.Info thisMixerInfo : AudioSystem.getMixerInfo()) {
            System.out.println("Mixer: " + thisMixerInfo.getDescription() +
                    " [" + thisMixerInfo.getName() + "]");
            Mixer thisMixer = AudioSystem.getMixer(thisMixerInfo);
            for (Line.Info thisLineInfo : thisMixer.getSourceLineInfo()) {
                if (thisLineInfo.getLineClass().getName().equals(
                        "javax.sound.sampled.Port")) {
                    Line thisLine = thisMixer.getLine(thisLineInfo);
                    thisLine.open();
                    System.out.println(" Source Port: "
                            + thisLineInfo.toString());
                    // for (Control thisControl : thisLine.getControls()) {
                    // System.out.println(AnalyzeControl(thisControl));
                    // }
                    thisLine.close();
                }
            }
            // for (Line.Info thisLineInfo : thisMixer.getTargetLineInfo()) {
            // if (thisLineInfo.getLineClass().getName().equals(
            // "javax.sound.sampled.Port")) {
            // Line thisLine = thisMixer.getLine(thisLineInfo);
            // thisLine.open();
            // System.out.println(" Target Port: "
            // + thisLineInfo.toString());
            // for (Control thisControl : thisLine.getControls()) {
            // System.out.println(AnalyzeControl(thisControl));
            // }
            // thisLine.close();
            // }
            // }
        }

        // Code to check buffer/available behavior:

        // System.out.println("");
        // for (int i = 0; i < 20; i++) {
        // System.out.println("Available: " + line.available());
        // System.out.println("Actual Frame#: " + line.getLongFramePosition());
        //
        // long currentNanos = System.nanoTime();
        // long microsPassed = (currentNanos - startNanos) / 1000;
        // long predictedFrame = (long) (microsPassed * ((outputFormat.getSampleRate() / 1000.0) / 1000.0));
        // System.out.println("Predicted Frame#: " + predictedFrame);
        // System.out.println("");
        //
        // try {
        // Thread.sleep(10);
        // } catch (InterruptedException e) {
        //
        // }
        // }
        //
        // line.write(outputBuffer, written, line.available());
        //
        // for (int i = 0; i < 70; i++) {
        // System.out.println("Available: " + line.available());
        // System.out.println("Frame#: " + line.getLongFramePosition());
        // try {
        // Thread.sleep(10);
        // } catch (InterruptedException e) {
        //
        // }
        // }
        //
        // try {
        // Thread.sleep(1000);
        // } catch (InterruptedException e) {
        //
        // }

        System.out.println();
        System.out.println();

        // AudioInputStream inputStream = AudioSystem.getAudioInputStream(new File("/home/emulder/Downloads/owl.wav"));
        // SourceDataLine line = AudioSystem.getSourceDataLine(inputStream.getFormat(), AudioSystem.getMixerInfo()[6]);
        // line.open(inputStream.getFormat());
        // AudioOutputStream outputStream = new AudioOutputStream(line);

        // Idea: use a queue for the chunks
        // final LinkedList<byte[]> queue = new LinkedList<>();

        // final Mixer mixer = AudioSystem.getMixer(null);
        File url = new File(FILEPATH);
        final AudioInputStream stream = AudioSystem.getAudioInputStream(url);
        // final AudioFormat format = stream.getFormat();
        byte[] buffer;
        int size = 12534336;
        stream.read(buffer = new byte[size], 0, size);

        AudioFormat inputFormat = stream.getFormat();
        // Explicitly set to stereo to control each speaker individually.
        AudioFormat outputFormat = new AudioFormat(inputFormat.getEncoding(), inputFormat.getSampleRate(), inputFormat.getSampleSizeInBits(),
                2, 4, inputFormat.getFrameRate(), inputFormat.isBigEndian());
        System.out.println("Input  format: " + inputFormat);
        System.out.println("Output format: " + outputFormat);

        // Index 1 has buffer of 32768 which becomes available again in steps of about 2000.
        // Index 6 has buffer of 48000 which becomes available again in steps of 1920, which neatly matches a play time of 20 millis.
        // The above is true for 24000.0 Hz, 16 bit, stereo, but it will be exactly half when choosing mono.
        // So it seems like the underlying implementation actually chooses to have a buffer of a certain amount of millis (differs per line),
        // while also having a buffer chunk size of about 20 millis playtime
        // Index 0 has buffer size of 48000, but available can be higher!

        // You can also get the current frame from the line and you can predict the current frame based on the real time.
        // Impossible to match up exactly, cause you don't know when it starts playing, given the write to buffer function.
        // But the diff seems to stay intact quite nicely. Although it may be very worthwhile to stay in sync using the real time, so slight thread
        // based differences will not grow over time and sometimes a frame is skipped or duplicated when needed to keep all lines in sync.
        // For index 1 the actual vs predict works quite nicely, for 0 it's a mess (again). For 6 it's quite ok, only the actual frame resolution is times 120

        // 0 = 3D sound
        // 1 = internal speakers
        // 6 = virtual 7.1 (seems to have left/right different then 3D sound)

        SourceDataLine line = AudioSystem.getSourceDataLine(outputFormat, AudioSystem.getMixerInfo()[DEVICE_INDEX]);
        System.out.println("line class: " + line.getClass());
        // SourceDataLine line = (SourceDataLine) mixer.getLine(new DataLine.Info(SourceDataLine.class, format));
        line.open();
        System.out.println("Available: " + line.available());
        System.out.println("Buffer size: " + line.getBufferSize());

        long nextFrameToWrite = 0;

        // Start after first buffer write, so we are as much in sync with frame number as possible
        // TODO: start later? After first buffer write?
        boolean lineStarted = false;

        // Initial buffer fill
        NextChunk initialChunk = fillNextChunk2(inputFormat, buffer, outputFormat, nextFrameToWrite, -1, -1, 0);
        line.write(initialChunk.buffer, 0, initialChunk.buffer.length);
        nextFrameToWrite = initialChunk.nextFrameToWrite;

        long startNanos = 0;

        // 'music loop'
        for (int i = 0; i < 20000; i++) {
            if (!lineStarted) {
                // This is the important syncing point: startNanos should be defined as close as possible to line.start(),
                // cause that is when the music starts playing. Furthermore, there should already be some buffer filling, otherwise
                // the line.start() will not actually start playing anything.
                // TODO: Can be even closer when using listener + LineEvent.Type.START
                startNanos = System.nanoTime();
                line.start();
                lineStarted = true;
            }

            // int mouseX = MouseInfo.getPointerInfo().getLocation().x;
            // double balance = mouseX / 1920.0;
            // System.out.println("Balance: " + balance);
            NextChunk nextChunk = fillNextChunk2(inputFormat, buffer, outputFormat, nextFrameToWrite, -1, startNanos, line.getFramePosition());

            line.write(nextChunk.buffer, 0, nextChunk.buffer.length);
            // TODO: anything with availability checks? Or just assume there is always enough room for a few millis extra? If not, write will just block until
            // there is room, which is not a big deal,
            // just not always sleep for BUFFER_CHUNK_IN_MILLIS, but pre-calculate the amount of millis needed base on current time.
            nextFrameToWrite = nextChunk.nextFrameToWrite;

            // System.out.println("line frame: " + line.getFramePosition());
            // System.out.println("next frame to be written: " + nextFrameToWrite);
            // System.out.println("Diff: " + (nextFrameToWrite - line.getFramePosition()));
            // System.out.println("line micros: " + line.getMicrosecondPosition());

            // TODO: dynamic sleep based on current time
            // long currentNanos = System.nanoTime();
            // int millisToSleep = Math.round(a)
            try {
                // if (Math.random() > 0.99) {
                // System.out.println("Draining!");
                // Thread.sleep(1000);
                // } else {
                Thread.sleep(BUFFER_CHUNK_IN_MILLIS);
                // }
            } catch (InterruptedException e) {

            }

        }

        line.close();

    }

    // Too high values will get us into a blocking write for most of the time!
    // And that blocking will actually cause quite a long wait, so should be avoided.
    static int INITIAL_BUFFER_IN_MILLIS = 100;
    static int BUFFER_CHUNK_IN_MILLIS = 1;
    static int DEVICE_INDEX = 6;
    static String FILEPATH = "/home/emulder/Downloads/game-music-mono-44k.wav";

    private static NextChunk fillNextChunk2(AudioFormat inputFormat, byte[] inputBuffer, AudioFormat outputFormat,
            long nextFrameToWrite, int millis, long startNanos, long lineCurrentFrame) {

        int framesPerMilli = (int) (inputFormat.getSampleRate() / 1000);
        long toFrame;
        // TODO split otherwise
        if (millis > 0) {
            toFrame = nextFrameToWrite + (framesPerMilli * millis);
        } else {
            // Works very well when the actual playback didn't have any interruption / pause,
            // but will result in a way too large buffer when it does.
            // TODO: ideally, you do want to take the actual frame from the line into account,
            // even if a single read is not very accurate, the 'stream' of reads gives a pretty nice idea of the state of the line
            // TODO: balance the buffer to add based on the diff might be a great idea

            // long currentNanos = System.nanoTime();
            // long nanosSinceStart = currentNanos - startNanos;
            // double framesPerNano = inputFormat.getSampleRate() / 1000.0 / 1000.0 / 1000.0;
            // long soundShouldBeAtFrame = (long) (framesPerNano * nanosSinceStart);
            // toFrame = soundShouldBeAtFrame + ((INITIAL_BUFFER_IN_MILLIS + BUFFER_CHUNK_IN_MILLIS) * framesPerMilli);

            // This actually works good enough! It is depending on the hardware to give the current frame number in a high
            // enough resolution. Improvement would be to always up a bit, to compensate for missing data. For instance:
            // Calculate the average upping of the loop over a small init period and use that when nothing changed in line frame position.
            // That will improve the resolution of the dynamic changes and also could be used to lower amount to be buffered.

            // There seems to be a lower barrier of buffer needed to play (or prob hardware/sofware just pauses when that limit is hit).
            // For index 1 (internal speakers) this is 20 ms left in buffer, then it starts to stutter, with 21 ms left it's perfectly ok.
            // Possible nice feature: test run all sound cards to find the lowest common possible value for all cards, using just silent sound bytes.
            // Start with high amountOfFramesToBuffer and lower till stutter is detected (reported line frame has high mismatch with predicted nanos)
            // Seems like card index 0 has behavior: just stop completely when buffer is found to be empty. -> maybe detectable with listener?
            // (playback stopped event) and able to re-trigger to play?
            // Card with index 6 also has strange behavior when buffer approaches 20 ms: it just skips a few hundred frames and then is without buffer.
            // a bit higher is ok, smooth playback.

            // A very short sleep causes the allowed amountOfFramesToBuffer to drop, since it's filled up quicker and doesn't reach the 'lower threshold'
            // so easily. Sweet spot for the whole system is probably to use a bit of slack above the threshold and keep the sleep pretty low, but not
            // extremely low.

            // test if this is frame or milli related!!! Use wav file with 44/48 KHz to check
            // result: For index 1 quite consistent. So cutoff point seems to be in millis, although other frequencies can go a little lower than 20 ms.
            // Is the most sane approach, looking at the big difference in possible sample rates
            // Total buffer size is clearly related to sample size.
            // result: for index 6 same consistent behavior: when buffer has a little less then 20ms left, will start to fail
            // interesting observation: just above the cutoff point there were single failures after about 10 seconds, but a little higher still no more
            // problems. But in this case a very small percentage above the cutoff gives very smooth playback again 396 vs 410
            // But at higher sample rates the possible millis left in buffer can actually drop quite a lot. So maybe it's a combi of
            // at least 20 millis or x frames/bytes? Either way, we can detect the starting failure quite easily, so we can always calibrate.
            // Other funny finding: small failures at high sampling rates cannot be heard 'with the naked ear' :)
            // So an extra safety percentage above the cutoff point is not just a luxury, but it does not need to be very high.
            // result: for index 0 at a high sample rate we need 25 ms in buffer, same for 22k SR, same for 8K, very consistent behavior actually
            // Actually it just needs something left in the buffer and only needs a bigger one cause it updates it's frame pos so crappy

            // And also: does the line frame match the nanos diff? Or at least over time? --> will implement later

            // General measure of Soundcard quality:
            // 1. Resolution of frame updates: measure current line frame as often as possible and save the max diff (and avg diff?)
            // 2. How empty can the buffer be (bytes / ms) before stuttering starts to happen? (partly influenced by 1. how accurate you can measure this)
            // 2b. Does playback resume with some little hickups or stop entirely?
            // 3. Does the playback speed match the real life time + sample rate? (how much difference / one way / both ways?) (partly influenced by 1. how
            // accurate you can measure this)
            // And all of this for all of the possible sample rates: 8k, 11k, 16k, 22k, 32k, 44k, 48k (and maybe even 8/16 bit)
            // Should be needed only once per sound card/speaker setup. Plus is pretty cool to make it audible and visible: what an advanced self
            // configuring system!

            long amountOfFramesToBuffer = 1100;
            long amountOfFramesNeeded = amountOfFramesToBuffer - (nextFrameToWrite - lineCurrentFrame);
            toFrame = nextFrameToWrite + amountOfFramesNeeded;
            System.out.println("amountOfFramesNeeded: " + amountOfFramesNeeded);
            long millisLeftInBuffer = (amountOfFramesToBuffer - amountOfFramesNeeded) / framesPerMilli;
            System.out.println("millis left in buffer: " + millisLeftInBuffer);
            if (millisLeftInBuffer == 0) {
                System.out.println("millis 0 at line frame: " + lineCurrentFrame);
            }
            // TODO: fix this weird hack somehow, occurs when there is more or equal buffer than needed (2nd pass, initial buffer intact)
            // Could also happen when actual frame not updated since last time.
            if (toFrame <= nextFrameToWrite) {
                // Just add 1 frame to be written as workaround for this issue, might rather be a total skip eventually
                toFrame = nextFrameToWrite + 1;
            }
        }

        int nextChunkSize = (int) ((toFrame - nextFrameToWrite) * outputFormat.getFrameSize());
        // System.out.println("Chunk size: " + nextChunkSize);
        byte[] outputBuffer = new byte[nextChunkSize];
        for (long f = nextFrameToWrite; f < toFrame; f++) {
            int startByteInInputBuffer = (int) (inputFormat.getFrameSize() * f);
            int startByteInOutputBuffer = (int) (outputFormat.getFrameSize() * (f - nextFrameToWrite));

            outputBuffer[startByteInOutputBuffer] = 0;
            outputBuffer[startByteInOutputBuffer + 1] = 0;
            outputBuffer[startByteInOutputBuffer + 2] = inputBuffer[startByteInInputBuffer];
            outputBuffer[startByteInOutputBuffer + 3] = inputBuffer[startByteInInputBuffer + 1];
        }
        NextChunk chunk = new NextChunk();
        chunk.nextFrameToWrite = toFrame;
        chunk.buffer = outputBuffer;
        return chunk;
    }

    // TODO: fix the sliding frame logic!!
    private static NextChunk fillNextChunk(AudioFormat inputFormat, byte[] inputBuffer, AudioFormat outputFormat, long startNanos, long nextFrameToWrite,
            double balance, boolean lineStarted) {
        long currentNanos = System.nanoTime();
        long microsPassed = (currentNanos - startNanos) / 1000;
        long predictedCurrentFrame = (long) (microsPassed * ((outputFormat.getSampleRate() / 1000.0) / 1000.0));
        predictedCurrentFrame += (outputFormat.getSampleRate() / 1000.0) * (INITIAL_BUFFER_IN_MILLIS + BUFFER_CHUNK_IN_MILLIS);
        long amountOfFramesToWrite = predictedCurrentFrame - nextFrameToWrite;
        if (!lineStarted) {
            amountOfFramesToWrite = (long) ((outputFormat.getSampleRate() / 1000.0) * INITIAL_BUFFER_IN_MILLIS);
            predictedCurrentFrame = amountOfFramesToWrite;
        }
        int nextChunkSize = (int) (amountOfFramesToWrite * outputFormat.getFrameSize());
        byte[] outputBuffer = new byte[nextChunkSize];
        System.out.println(
                "about to write: " + (predictedCurrentFrame - nextFrameToWrite) + " frames (" + nextFrameToWrite + " - " + predictedCurrentFrame + ")");
        for (long f = nextFrameToWrite; f < predictedCurrentFrame; f++) {
            // if (f % 100 == 0)
            // System.out.println("Frame: " + f);
            // TODO: assumption that the input buffer is always the complete array, should be (possibly) chunked too.
            int startByteInInputBuffer = (int) (inputFormat.getFrameSize() * f);
            int startByteInOutputBuffer = (int) (outputFormat.getFrameSize() * (f - nextFrameToWrite));
            double volumeForLeftSpeaker = 1 - balance;
            double volumeForRightSpeaker = balance;

            final byte[] sample = new byte[2];
            System.arraycopy(inputBuffer, startByteInInputBuffer, sample, 0, 2);
            short amplitude = ByteBuffer.wrap(sample).order(inputFormat.isBigEndian() ? ByteOrder.BIG_ENDIAN : ByteOrder.LITTLE_ENDIAN).getShort();

            short leftAmplitude = (short) (amplitude * volumeForLeftSpeaker);
            short rightAmplitude = (short) (amplitude * volumeForRightSpeaker);

            /*
             * Little endian:
             * ret[0] = (byte)(x & 0xff);
             * ret[1] = (byte)((x >> 8) & 0xff);
             * Big endian:
             * byte[] arr=new byte[]{(byte)((x>>8)&0xFF),(byte)(x&0xFF)}
             */

            // byte[] leftBytes = new byte[] { (byte) ((leftAmplitude >> 8) & 0xFF), (byte) (leftAmplitude & 0xFF) };
            // byte[] rightBytes = new byte[] { (byte) ((rightAmplitude >> 8) & 0xFF), (byte) (rightAmplitude & 0xFF) };

            byte[] leftBytes = new byte[] { (byte) (leftAmplitude & 0xff), (byte) ((leftAmplitude >> 8) & 0xff) };
            byte[] rightBytes = new byte[] { (byte) (rightAmplitude & 0xff), (byte) ((rightAmplitude >> 8) & 0xff) };

            outputBuffer[startByteInOutputBuffer] = leftBytes[0];
            outputBuffer[startByteInOutputBuffer + 1] = leftBytes[1];
            outputBuffer[startByteInOutputBuffer + 2] = rightBytes[0];
            outputBuffer[startByteInOutputBuffer + 3] = rightBytes[1];
        }
        NextChunk chunk = new NextChunk();
        chunk.nextFrameToWrite = predictedCurrentFrame;
        chunk.buffer = outputBuffer;
        return chunk;
    }

    private static class NextChunk {
        private long nextFrameToWrite;
        private byte[] buffer;
    }

}
